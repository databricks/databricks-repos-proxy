{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "09428fe1-c76a-4d03-8deb-acbd94050594",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "# Enable Git Proxy for private Git server connectivity in Repos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "d139a95c-8953-4a5a-8373-38e0d52b084a",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "### Overview\n",
    "This private preview feature is available on AWS, Azure and GCP.\n",
    "\n",
    "**Note**: an *admin* must run this notebook to enable the feature.\n",
    "\n",
    "\"Run all\" this notebook to set up a cluster that proxies requests to your private Git server. Running this notebook does the following things:\n",
    "\n",
    "0. Creates a [single node cluster](https://docs.databricks.com/clusters/single-node.html) to run Git Proxy on it.\n",
    "0. Enables a feature flag that controls whether Git requests in Repos are proxied via the cluster.\n",
    "\n",
    "You may need to wait several minutes after running this notebook for the cluster to reach a \"RUNNING\" state. It can also take up to 5 minutes for the feature flag configuration to take effect."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "edad2001-6adf-47bb-a3af-34ff028e0d15",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%pip install databricks-sdk==0.9.0\n",
    "dbutils.library.restartPython()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "4e1623df-034f-4853-b544-cf70a491702d",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "## Create the proxy cluster"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "48beb9ca-d6a5-4ebd-9370-17035d3af9de",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "#### Setup admin token and HTTP requests\n",
    "Get the admin token from current context, prepare HTTP requests for Databricks APIs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "89b4e13d-8cbb-48e9-8d59-5f4ec85a8eb1",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "from databricks.sdk import WorkspaceClient\n",
    "from databricks.sdk.core import ApiClient\n",
    "from databricks.sdk.service import compute\n",
    "from databricks.sdk.service import iam\n",
    "from databricks.sdk.service.compute import AwsAttributes, AzureAttributes, GcpAttributes\n",
    "w = WorkspaceClient()\n",
    "api_client = ApiClient()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8582806d-7447-4f08-b93d-da8e01cacda8",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "cluster_name = \"Repos Git Proxy\"\n",
    "\n",
    "create_cluster_data = {\n",
    "    \"cluster_name\": cluster_name,\n",
    "    \"spark_version\": \"12.2.x-scala2.12\",\n",
    "    \"autotermination_minutes\": 0,\n",
    "    \"num_workers\": 0,\n",
    "    \"spark_conf\": {\n",
    "        \"spark.databricks.cluster.profile\": \"singleNode\",\n",
    "        \"spark.master\": \"local[*]\",\n",
    "    },\n",
    "    \"custom_tags\": {\"ResourceClass\": \"SingleNode\"},\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "2a33316f-5212-4561-b3f0-d971d3fdc619",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "#### Create the cluster\n",
    "Call Databricks Cluster API to create the Git Proxy cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d8fd703a-9e45-4503-bb1a-7d2150846cbd",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# get list of node types to determine whether this workspace is on AWS or Azure\n",
    "nodes = w.clusters.list_node_types()\n",
    "node_type_ids = [t.node_type_id for t in nodes.node_types]\n",
    "aws_node_type_id = \"m5.large\"\n",
    "azure_node_type_id = \"Standard_DS3_v2\"\n",
    "gcp_node_type_id = \"e2-standard-4\"\n",
    "\n",
    "if w.config.is_aws:\n",
    "    if aws_node_type_id not in node_type_ids:\n",
    "        raise ValueError(\n",
    "            f\"Node types {aws_node_type_id} does not exist in your workspace. Make sure the node type specified is available in your workspace, or contact support.\"\n",
    "        )\n",
    "    node_type_id = aws_node_type_id\n",
    "    create_cluster_data[\"aws_attributes\"] = AwsAttributes.from_dict({\"ebs_volume_count\": \"1\", \"ebs_volume_size\": \"32\", \"first_on_demand\": \"1\"})\n",
    "elif w.config.is_azure:\n",
    "    if azure_node_type_id not in node_type_ids:\n",
    "        raise ValueError(\n",
    "            f\"Node types {azure_node_type_id} does not exist in your workspace. Make sure the node type specified is available in your workspace, or contact support.\"\n",
    "        )\n",
    "    node_type_id = azure_node_type_id\n",
    "    create_cluster_data[\"azure_attributes\"] = AzureAttributes.from_dict({\n",
    "                        \"availability\": \"ON_DEMAND_AZURE\"\n",
    "                        })\n",
    "    \n",
    "elif w.config.is_gcp:\n",
    "    if gcp_node_type_id not in node_type_ids:\n",
    "        raise ValueError(\n",
    "            f\"Node types {gcp_node_type_id} does not exist in your workspace. Make sure the node type specified is available in your workspace, or contact support.\"\n",
    "        )\n",
    "    node_type_id = gcp_node_type_id\n",
    "    create_cluster_data[\"gcp_attributes\"] = GcpAttributes.from_dict({\n",
    "            \"use_preemptible_executors\": False\n",
    "            })\n",
    "else: \n",
    "   raise ValueError(\n",
    "        f\"The Databricks git proxy server only supports AWS, Azure and GCP. Running on an unsupported cloud. Please contact support.\"\n",
    "    )\n",
    "\n",
    "create_cluster_data[\"node_type_id\"] = node_type_id\n",
    "\n",
    "\n",
    "# Note: Return information about all pinned clusters, active clusters, up to 200 of the most recently terminated all-purpose clusters in the past 30 days, and up to 30 of the most recently terminated job clusters in the past 30 days. See https://github.com/databricks/databricks-sdk-py/blob/349216706aeac81828a807f40a21a1b0c80ed717/docs/workspace/clusters.rst?plain=1#L592\n",
    "all_clusters = w.clusters.list()\n",
    "clusters_names = [c.cluster_name for c in all_clusters]\n",
    "print(f\"List of existing clusters: {clusters_names}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "if cluster_name in clusters_names:\n",
    "    raise ValueError(\n",
    "        f\"Cluster called {cluster_name} already exists. Please delete this cluster and re-run this notebook\"\n",
    "    )\n",
    "else:\n",
    "    # Create a new cluster named cluster_name that will proxy requests to the private Git server\n",
    "    print(f\"Create cluster POST request data: {create_cluster_data}\")\n",
    "    clusters_create_response = w.clusters.create(**create_cluster_data).result()\n",
    "    print(f\"Create cluster response: {clusters_create_response}\")\n",
    "    cluster_id = clusters_create_response.cluster_id\n",
    "    print(f\"Created new cluster with id {cluster_id}\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "cec1268f-5134-4bf5-9fc0-23140492558b",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "## Flip the feature flag!\n",
    "This flips the feature flag to route Git requests to the cluster. The change should take into effect within an hour."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0829abfd-638c-4db1-9da4-d2c9e219f53f",
     "showTitle": false,
     "title": ""
    },
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "api_client.do(\"PATCH\", \"/api/2.0/workspace-conf\", body={\"enableGitProxy\": \"true\"}, headers={\"Content-Type\": \"application/json\"})\n",
    "api_client.do(\"PATCH\", \"/api/2.0/workspace-conf\", body={\"gitProxyClusterId\": cluster_id}, headers={\"Content-Type\": \"application/json\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "814082f8-5526-4835-b864-0a426c1b6926",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "#### Check that flag has been set\n",
    "If the command below returns with `{\"enableGitProxy\":\"true\"}`, you should be all set. Also, if you configured a custom cluster name using the widget, check that the cluster name in the response matches the name you specified."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "68066546-21ff-4523-a5dc-9760b225474a",
     "showTitle": false,
     "title": ""
    },
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "get_flag_response = api_client.do(\"GET\", \"/api/2.0/workspace-conf\", {\"keys\": \"enableGitProxy\"})\n",
    "get_cluster_id_response = api_client.do(\"GET\", \"/api/2.0/workspace-conf\", {\"keys\": \"gitProxyClusterId\"})\n",
    "print(f\"Get enableGitProxy response: {get_flag_response}\")\n",
    "print(f\"Get gitProxyClusterId response: {get_cluster_id_response}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "735e9217-6cd7-41b2-9d7a-0caf3a19d795",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "#### Confirm the cluster is ready\n",
    "You can check the cluster status at [Compute](#setting/clusters), the cluster name is \"Repos Git Proxy\"."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "9e944a34-e628-46be-b110-ba474ee48921",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "#### More configuration (only needed if the Git Proxy not working with default setup)\n",
    "You can configure Git Proxy to match your setup, edit the cluster, and go to Advanced options -> Spark -> Environment variables. Supported environment variables are:\n",
    "- GIT_PROXY_ENABLE_SSL_VERIFICATION: You may want to disable SSL verification if you are using a self-signed certificate for your private Git server. Example: true/false\n",
    "- GIT_PROXY_CA_CERT_PATH: Or you can provide a CA cert file for SSL verification.\n",
    "- GIT_PROXY_HTTP_PROXY: If your data plane requires HTTP proxy for all HTTP trafic. Example: https://localhost:3128\n",
    "- GIT_PROXY_CUSTOM_HTTP_PORT: If your Git server has non-standard HTTPS port. Example: 8443\n",
    "\n",
    "After updating the environment variables, please save and restart the cluster."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "44084ca1-996a-4b84-9d44-55e73196a275",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "## Flip the feature flag back if you are just testing\n",
    "Please note that if you are just testing the proxy, make sure you keep the proxy cluster on during your test. Once the test finishes, you need to change the config back in order to restore the original behavior.\n",
    "\n",
    "The step below undoes the config change to reroute Git requests. The change should take into effect within an hour."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "6d25ff37-472b-4e02-9f34-1270c9c971a9",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# api_client.do(\"PATCH\", \"/api/2.0/workspace-conf\", body={\"enableGitProxy\": \"false\"}, headers={\"Content-Type\": \"application/json\"})"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [],
   "language": "python",
   "notebookMetadata": {
    "mostRecentlyExecutedCommandWithImplicitDF": {
     "commandId": 1649133805813433,
     "dataframes": [
      "_sqldf"
     ]
    },
    "pythonIndentUnit": 4,
    "widgetLayout": []
   },
   "notebookName": "enable_git_proxy_jupyter",
   "widgets": {}
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
